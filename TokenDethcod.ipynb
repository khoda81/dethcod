{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSX4vKTl97pS",
        "outputId": "64d713f1-32ad-4db4-ef37-e338a7a4e841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.0)\n",
            "Requirement already satisfied: requests_cache in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.3.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests_cache) (23.2.0)\n",
            "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.10/dist-packages (from requests_cache) (23.2.3)\n",
            "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.10/dist-packages (from requests_cache) (1.4.3)\n",
            "Requirement already satisfied: urllib3>=1.25.5 in /usr/local/lib/python3.10/dist-packages (from requests_cache) (2.0.7)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests_cache) (1.2.1)\n",
            "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests_cache) (4.11.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers wandb requests_cache datasets tqdm python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yDIICSsnFOb"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQb9wuBJnFOc",
        "outputId": "e2d53ae0-a602-4e1a-cc30-929920b959dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|██████████| 36.4M/36.4M [00:00<00:00, 431MB/s]\n",
            "File downloaded and decompressed successfully.\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "\n",
        "import requests\n",
        "import requests_cache\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "zip_link = \"http://www.mattmahoney.net/dc/enwik8.zip\"\n",
        "data_folder = \"dataset\"\n",
        "cache_file = \"download_cache\"\n",
        "\n",
        "# Ensure the data folder exists\n",
        "if not os.path.exists(data_folder):\n",
        "    os.makedirs(data_folder)\n",
        "\n",
        "# Initialize requests_cache\n",
        "requests_cache.install_cache(os.path.join(data_folder, cache_file))\n",
        "\n",
        "# Download the ZIP file with progress bar\n",
        "response = requests.get(zip_link, stream=True)\n",
        "response.raise_for_status()\n",
        "\n",
        "# Get the total file size for the progress bar\n",
        "total_size = int(response.headers.get(\"content-length\", 0))\n",
        "\n",
        "# Open the ZIP file from the content\n",
        "with open(os.path.join(data_folder, \"enwik8.zip\"), \"wb\") as file:\n",
        "    with tqdm(\n",
        "        total=total_size, unit=\"B\", unit_scale=True, desc=\"Downloading\"\n",
        "    ) as pbar:\n",
        "        for data in response.iter_content(chunk_size=1024):\n",
        "            file.write(data)\n",
        "            pbar.update(len(data))\n",
        "\n",
        "# Open the cached file\n",
        "with open(os.path.join(data_folder, \"enwik8.zip\"), \"rb\") as file:\n",
        "    # Open the ZIP file from the content\n",
        "    with zipfile.ZipFile(io.BytesIO(file.read())) as zip_file:\n",
        "        # Extract all contents to the data folder\n",
        "        zip_file.extractall(data_folder)\n",
        "\n",
        "print(\"File downloaded and decompressed successfully.\", file=sys.stderr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMCRynUDpAz6"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BF26H2PapAjj"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"text\", data_files=[\"dataset/enwik8\"])\n",
        "dataset = dataset[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY1_Ux8uprdh",
        "outputId": "c2b8a9e8-08bd-4e6a-a051-9250780cc27b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "MODEL_ID = \"google-t5/t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dZXhU0AfhrTJ"
      },
      "outputs": [],
      "source": [
        "# Removing large and empty samples\n",
        "# TODO: speed up filtering by batch tokenizing\n",
        "max_len = 128\n",
        "\n",
        "def filter_samples(example):\n",
        "    length = len(tokenizer(example['text'])['input_ids'])\n",
        "    return 1 < length <= max_len\n",
        "\n",
        "dataset = dataset.filter(filter_samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPWUhHX8A43h",
        "outputId": "099a0d8a-60f5-435b-fdc4-e135e3c4ff93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'{{commonscat|Gerard David}}'\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "sample = random.choice(dataset)\n",
        "print(repr(sample[\"text\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrDpshHUnFOd"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fGqAZ6NY-FrU"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, Union\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "import transformers.modeling_outputs\n",
        "\n",
        "\n",
        "class CompressionConfig(transformers.T5Config): ...\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CompressionOutput(transformers.modeling_outputs.Seq2SeqLMOutput):\n",
        "    value_predictions: Optional[Tuple[torch.FloatTensor, ...]] = None\n",
        "\n",
        "\n",
        "class CompressionModel(transformers.T5ForConditionalGeneration):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.critic_head = nn.Linear(config.d_model, 1)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.LongTensor] = None,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.BoolTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        decoder_head_mask: Optional[torch.FloatTensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
        "        past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = True,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple[torch.FloatTensor], CompressionOutput]:\n",
        "        output = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            decoder_head_mask=decoder_head_mask,\n",
        "            cross_attn_head_mask=cross_attn_head_mask,\n",
        "            encoder_outputs=encoder_outputs,\n",
        "            past_key_values=past_key_values,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
        "            labels=labels,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        if output.decoder_hidden_states is not None:\n",
        "            last_hidden_state = output.decoder_hidden_states[-1]\n",
        "            value_predictions = self.critic_head(last_hidden_state)\n",
        "        else:\n",
        "            value_predictions = None\n",
        "\n",
        "        return CompressionOutput(\n",
        "            value_predictions=value_predictions,\n",
        "            logits=output.logits,\n",
        "            past_key_values=output.past_key_values,\n",
        "            decoder_hidden_states=output.decoder_hidden_states,\n",
        "            decoder_attentions=output.decoder_attentions,\n",
        "            cross_attentions=output.cross_attentions,\n",
        "            encoder_last_hidden_state=output.encoder_last_hidden_state,\n",
        "            encoder_hidden_states=output.encoder_hidden_states,\n",
        "            encoder_attentions=output.encoder_attentions,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XMVtNmiu-30c"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import transformers.modeling_outputs\n",
        "\n",
        "\n",
        "class DecompressionConfig(transformers.T5Config): ...\n",
        "\n",
        "\n",
        "class DecompressionModel(transformers.T5ForConditionalGeneration): ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeKAyrQz5k_k"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OTuhuS295RZ",
        "outputId": "80eb955b-6f1f-4899-df53-f06c5bcda115"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CompressionModel were not initialized from the model checkpoint at google-t5/t5-small and are newly initialized: ['critic_head.bias', 'critic_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "compressor = CompressionModel.from_pretrained(MODEL_ID).to(device)\n",
        "decompressor = DecompressionModel.from_pretrained(MODEL_ID).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "nbJccLQa_TKV"
      },
      "outputs": [],
      "source": [
        "LR = 1e-6\n",
        "\n",
        "compressor_optimizer = torch.optim.Adam(compressor.parameters(), lr=LR)\n",
        "decompressor_optimizer = torch.optim.Adam(decompressor.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "zioTdU4gA2J2"
      },
      "outputs": [],
      "source": [
        "# TODO: increase batch size\n",
        "batch_size = 1\n",
        "train_dataset = dataset\n",
        "data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a0678d2428ff4198a9381b664dea08c4",
            "579d2c20323a4e14aa0b2fcc125e9eb9",
            "1a79263283254ba3a8e909ea3966e3ac",
            "e4dcb7f644ce4739b255809f9df0bf53",
            "584d3bd4ac484269bcf7da1d48c78448",
            "e648ad71485b482992d3b5b699fdf90b",
            "a7c81547e14040a28b9f3e8f469bc933",
            "460431870cd346caa15e02b9ffe0c63f",
            "a75e62964f224e8ab32e9136c00f786e",
            "6f20c7b7089045ffa62fda32898dd673",
            "e79223029d27455288e6daa49aabe4f3"
          ]
        },
        "id": "-71bvb9b4Rth",
        "outputId": "058aeb31-300b-4aef-e930-5421113cbff1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0678d2428ff4198a9381b664dea08c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/855090 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "import tqdm.auto as tqdm\n",
        "from transformers import GenerationConfig\n",
        "from transformers import modeling_outputs\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    do_sample=True,\n",
        "    num_beams=1,\n",
        "    max_new_tokens=100,\n",
        "    # output_scores = True,\n",
        "    decoder_start_token_id = compressor.generation_config.decoder_start_token_id,\n",
        "    eos_token_id = compressor.generation_config.eos_token_id,\n",
        "    pad_token_id = compressor.generation_config.pad_token_id,\n",
        ")\n",
        "\n",
        "with tqdm.tqdm(data_loader) as pbar:\n",
        "    for batch in pbar:\n",
        "        input_ids = tokenizer(batch['text'], return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(device)\n",
        "\n",
        "        compressed = compressor.generate(\n",
        "            input_ids=input_ids,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "\n",
        "        compression_output = compressor.forward(\n",
        "            input_ids=input_ids,\n",
        "            decoder_input_ids=compressed,\n",
        "        )\n",
        "\n",
        "        logits = compression_output.logits\n",
        "\n",
        "        decompressed = decompressor.forward(\n",
        "            input_ids=compressed,\n",
        "            labels=input_ids,\n",
        "        )\n",
        "\n",
        "        num_ids = decompressed.logits.size(-1)\n",
        "        losses = F.cross_entropy(\n",
        "            decompressed.logits.view(-1, num_ids),\n",
        "            target=input_ids.view(-1),\n",
        "            ignore_index=0,\n",
        "            reduction='none',\n",
        "        )\n",
        "\n",
        "        TOKEN_COST = 1\n",
        "        len_compressed = compressed.shape[1]\n",
        "        reward = -TOKEN_COST * len_compressed - losses.detach().sum()\n",
        "\n",
        "        value = compression_output.value_predictions.squeeze(-1)\n",
        "        value = value[..., :-1]\n",
        "        Q = torch.ones_like(value) * reward\n",
        "\n",
        "        advantage = Q - value\n",
        "\n",
        "        critic_loss = torch.nn.functional.mse_loss(value, Q, reduction='mean')\n",
        "\n",
        "        num_ids = logits.size(-1)\n",
        "        # TODO: add a negative sign if didn't work\n",
        "        action_logits = F.cross_entropy(\n",
        "            logits[:, :-1].view(-1, num_ids),\n",
        "            target=compressed[:, 1:].view(-1),\n",
        "            ignore_index=0,\n",
        "            reduction='none',\n",
        "        )\n",
        "\n",
        "        actor_loss = (advantage.detach() * action_logits).mean()\n",
        "        decompressor_loss = losses.mean()\n",
        "        pbar.set_description(f\"actor_loss={actor_loss:.2f}, critic_loss={critic_loss:.2f}, decompressor_loss={decompressor_loss:.2f}\")\n",
        "\n",
        "        compressor_optimizer.zero_grad()\n",
        "        decompressor_optimizer.zero_grad()\n",
        "\n",
        "        (actor_loss + critic_loss).backward()\n",
        "        decompressor_loss.backward()\n",
        "\n",
        "        compressor_optimizer.step()\n",
        "        decompressor_optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWtEiSe0RZqa",
        "outputId": "e2b87961-8603-48e7-9a72-fecfd1ebec4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len_compressed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eZwcIzrRUag",
        "outputId": "52b4cf58-f7dc-4439-d9c0-32cb75410cdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "         -282.6220, -282.6220, -282.6220, -282.6220]], device='cuda:0',\n",
              "       grad_fn=<SubBackward0>)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advantage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "khjZDzpROCEd"
      },
      "outputs": [],
      "source": [
        "del compressor, decompressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2T85EARPdwI",
        "outputId": "bc324f8e-e86a-44c4-ab3b-a95c72b1cae3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "odict_keys(['logits', 'past_key_values', 'decoder_hidden_states', 'encoder_last_hidden_state', 'encoder_hidden_states', 'value_predictions'])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compression_output.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLVMLQIqQXCf",
        "outputId": "01a7d128-c502-49f3-9556-fc948ee1f1ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.2774, 1.0894, 0.6197, 1.3383, 6.1276, 0.4534], device='cuda:0',\n",
              "       grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "action_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtKo3PPGQf0J",
        "outputId": "b0d3ea63-0a51-43ab-8fa2-e784c530ab45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-65.7736, -65.7736, -65.7736, -65.7736, -65.7736, -65.7736]],\n",
              "       device='cuda:0', grad_fn=<SubBackward0>)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advantage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXhr1x1tQhII",
        "outputId": "213f761f-3ea8-4f9a-e857-b7e3ac69a167"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ -8.6003,  -3.2641, -13.5006,  -8.6156,  -7.6396, -10.8533, -13.4743,\n",
              "         -1.4927,  -0.0933,  -5.2398], device='cuda:0', grad_fn=<NegBackward0>)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLAz9DwoN5np",
        "outputId": "b3931440-5067-4716-99b2-9421357bd608"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-282.6220, device='cuda:0')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIKY8_DwNa4l",
        "outputId": "bf6eb955-9a2a-4b57-8db4-6d86a7e94675"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len_compressed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zxqYdtCNLn7",
        "outputId": "fb8f9db0-ea93-4a70-be64-dbced88bc02b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[14.3322, 14.3322, 14.3322, 14.3322, 14.3322, 14.3322, 14.3322, 14.3322,\n",
              "         14.3322, 14.3322, 14.3322, 14.3322, 14.3322, 14.3322]],\n",
              "       device='cuda:0', grad_fn=<SubBackward0>)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advantage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDveEsAPMsQt",
        "outputId": "b2edf6d5-b6c8-44fa-99b8-13a4321b5afc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-511.4803, device='cuda:0', grad_fn=<MeanBackward0>)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "actor_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiJGEKx2MtlU",
        "outputId": "ad04d0e9-3976-418b-a74f-9a480ce1b48b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4451.5698, device='cuda:0', grad_fn=<MseLossBackward0>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "critic_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYiKrtM2M03J",
        "outputId": "ccf98ed3-034e-4363-e687-a08941c63c26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0.]], device='cuda:0', grad_fn=<SliceBackward0>),\n",
              " tensor([[-282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220, -282.6220, -282.6220,\n",
              "          -282.6220, -282.6220, -282.6220, -282.6220]], device='cuda:0'))"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "value, Q"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a79263283254ba3a8e909ea3966e3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_460431870cd346caa15e02b9ffe0c63f",
            "max": 855090,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a75e62964f224e8ab32e9136c00f786e",
            "value": 625
          }
        },
        "460431870cd346caa15e02b9ffe0c63f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "579d2c20323a4e14aa0b2fcc125e9eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e648ad71485b482992d3b5b699fdf90b",
            "placeholder": "​",
            "style": "IPY_MODEL_a7c81547e14040a28b9f3e8f469bc933",
            "value": "actor_loss=-113.94, critic_loss=3599.54, decompressor_loss=4.82:   0%"
          }
        },
        "584d3bd4ac484269bcf7da1d48c78448": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f20c7b7089045ffa62fda32898dd673": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0678d2428ff4198a9381b664dea08c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_579d2c20323a4e14aa0b2fcc125e9eb9",
              "IPY_MODEL_1a79263283254ba3a8e909ea3966e3ac",
              "IPY_MODEL_e4dcb7f644ce4739b255809f9df0bf53"
            ],
            "layout": "IPY_MODEL_584d3bd4ac484269bcf7da1d48c78448"
          }
        },
        "a75e62964f224e8ab32e9136c00f786e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7c81547e14040a28b9f3e8f469bc933": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4dcb7f644ce4739b255809f9df0bf53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f20c7b7089045ffa62fda32898dd673",
            "placeholder": "​",
            "style": "IPY_MODEL_e79223029d27455288e6daa49aabe4f3",
            "value": " 625/855090 [05:08&lt;110:21:56,  2.15it/s]"
          }
        },
        "e648ad71485b482992d3b5b699fdf90b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e79223029d27455288e6daa49aabe4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
