{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token based DETHCOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/khoda81/dethcod/blob/main/TokenDethcod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSX4vKTl97pS",
    "outputId": "64d713f1-32ad-4db4-ef37-e338a7a4e841",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      " - pytorch\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): - ^C\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install -c conda-forge transformers wandb requests_cache datasets tqdm python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "e-neGcFgTHdu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/khodabandeh/.netrc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    # Load environment variables from .env file\n",
    "    load_dotenv()\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing dotenv: {e}\")\n",
    "\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    # If running in Colab, use userdata.get to retrieve the token\n",
    "    wandb.login(key=userdata.get('wandb_token'))\n",
    "\n",
    "except ImportError:\n",
    "    # If not in Colab, load the token from the environment variable\n",
    "    wandb_token = os.getenv('WANDB_TOKEN')\n",
    "    if wandb_token:\n",
    "        wandb.login(key=wandb_token)\n",
    "    else:\n",
    "        print(\"W&B token not found in environment variable. Please set WANDB_TOKEN in your environment.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yDIICSsnFOb"
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQb9wuBJnFOc",
    "outputId": "e2d53ae0-a602-4e1a-cc30-929920b959dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████████████████████████| 36.4M/36.4M [00:00<00:00, 562MB/s]\n",
      "File downloaded and decompressed successfully.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "import requests_cache\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "zip_link = \"http://www.mattmahoney.net/dc/enwik8.zip\"\n",
    "data_folder = \"dataset\"\n",
    "cache_file = \"download_cache\"\n",
    "\n",
    "# Ensure the data folder exists\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "# Initialize requests_cache\n",
    "requests_cache.install_cache(os.path.join(data_folder, cache_file))\n",
    "\n",
    "# Download the ZIP file with progress bar\n",
    "response = requests.get(zip_link, stream=True)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Get the total file size for the progress bar\n",
    "total_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "# Open the ZIP file from the content\n",
    "with open(os.path.join(data_folder, \"enwik8.zip\"), \"wb\") as file:\n",
    "    with tqdm(\n",
    "        total=total_size, unit=\"B\", unit_scale=True, desc=\"Downloading\"\n",
    "    ) as pbar:\n",
    "        for data in response.iter_content(chunk_size=1024):\n",
    "            file.write(data)\n",
    "            pbar.update(len(data))\n",
    "\n",
    "# Open the cached file\n",
    "with open(os.path.join(data_folder, \"enwik8.zip\"), \"rb\") as file:\n",
    "    # Open the ZIP file from the content\n",
    "    with zipfile.ZipFile(io.BytesIO(file.read())) as zip_file:\n",
    "        # Extract all contents to the data folder\n",
    "        zip_file.extractall(data_folder)\n",
    "\n",
    "print(\"File downloaded and decompressed successfully.\", file=sys.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMCRynUDpAz6"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BF26H2PapAjj"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2d92ec2345473da4f8ded7320a6b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"text\", data_files=[\"dataset/enwik8\"])\n",
    "dataset = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pY1_Ux8uprdh",
    "outputId": "c2b8a9e8-08bd-4e6a-a051-9250780cc27b"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_ID = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dZXhU0AfhrTJ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f30d12561c04f76ade0d58f6f0bc753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1128024 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Removing large and empty samples\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "def filter_samples(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH + 1,\n",
    "        return_attention_mask=False,\n",
    "        return_length=True,\n",
    "    )\n",
    "\n",
    "    return [\n",
    "        1 < sample_length <= MAX_LENGTH\n",
    "        for sample_length in tokenized.length\n",
    "    ]\n",
    "\n",
    "dataset = dataset.filter(filter_samples, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPWUhHX8A43h",
    "outputId": "099a0d8a-60f5-435b-fdc4-e135e3c4ff93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'==The ideology=='\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "sample = random.choice(dataset)\n",
    "print(repr(sample[\"text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrDpshHUnFOd"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fGqAZ6NY-FrU"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import transformers.modeling_outputs\n",
    "\n",
    "\n",
    "class CompressionConfig(transformers.T5Config): ...\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CompressionOutput(transformers.modeling_outputs.Seq2SeqLMOutput):\n",
    "    value_predictions: Optional[Tuple[torch.FloatTensor, ...]] = None\n",
    "\n",
    "\n",
    "class CompressionModel(transformers.T5ForConditionalGeneration):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.critic_head = nn.Linear(config.d_model, 1)\n",
    "        self.critic_head.weight.data.normal_(mean=0.0, std=(1 / config.d_model))\n",
    "        self.critic_head.bias.data.zero_()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
    "        decoder_attention_mask: Optional[torch.BoolTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        decoder_head_mask: Optional[torch.FloatTensor] = None,\n",
    "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
    "        encoder_outputs: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = True,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.FloatTensor], CompressionOutput]:\n",
    "        output = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            decoder_head_mask=decoder_head_mask,\n",
    "            cross_attn_head_mask=cross_attn_head_mask,\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
    "            labels=labels,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        if output.decoder_hidden_states is not None:\n",
    "            last_hidden_state = output.decoder_hidden_states[-1]\n",
    "            value_predictions = self.critic_head(last_hidden_state).squeeze(-1)\n",
    "        else:\n",
    "            value_predictions = None\n",
    "\n",
    "        return CompressionOutput(\n",
    "            value_predictions=value_predictions,\n",
    "            logits=output.logits,\n",
    "            past_key_values=output.past_key_values,\n",
    "            decoder_hidden_states=output.decoder_hidden_states,\n",
    "            decoder_attentions=output.decoder_attentions,\n",
    "            cross_attentions=output.cross_attentions,\n",
    "            encoder_last_hidden_state=output.encoder_last_hidden_state,\n",
    "            encoder_hidden_states=output.encoder_hidden_states,\n",
    "            encoder_attentions=output.encoder_attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XMVtNmiu-30c"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import transformers.modeling_outputs\n",
    "\n",
    "\n",
    "class DecompressionConfig(transformers.T5Config): ...\n",
    "\n",
    "\n",
    "class DecompressionModel(transformers.T5ForConditionalGeneration): ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-OTuhuS295RZ",
    "outputId": "80eb955b-6f1f-4899-df53-f06c5bcda115"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = Path(\"./data/models/token-dethcod/a2c-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from google-t5/t5-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CompressionModel were not initialized from the model checkpoint at google-t5/t5-small and are newly initialized: ['critic_head.bias', 'critic_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "LOAD_ORIGINAL = True\n",
    "if LOAD_ORIGINAL:\n",
    "    model_path = \"google-t5/t5-small\"\n",
    "    print(f\"Loading model from {model_path}\")\n",
    "    compressor = CompressionModel.from_pretrained(model_path).to(device)\n",
    "    compressor.critic_head.reset_parameters()\n",
    "    decompressor = DecompressionModel.from_pretrained(model_path).to(device)\n",
    "else:\n",
    "    compressor = CompressionModel.from_pretrained(MODEL_PATH / \"compressor\").to(device)\n",
    "    decompressor = DecompressionModel.from_pretrained(MODEL_PATH / \"decompressor\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeKAyrQz5k_k"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SUo_c6cyTx2Y"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/khodabandeh/Projects/dethcod/wandb/run-20240806_152102-01oc9z80</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chihuahuas/DETHCOD/runs/01oc9z80' target=\"_blank\">Token Training</a></strong> to <a href='https://wandb.ai/chihuahuas/DETHCOD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chihuahuas/DETHCOD' target=\"_blank\">https://wandb.ai/chihuahuas/DETHCOD</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chihuahuas/DETHCOD/runs/01oc9z80' target=\"_blank\">https://wandb.ai/chihuahuas/DETHCOD/runs/01oc9z80</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/chihuahuas/DETHCOD/runs/01oc9z80?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f83b0a6eb40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    name = \"Token Training\",\n",
    "    project=\"DETHCOD\",\n",
    "    config={\n",
    "        \"compressor_model_config\": compressor.config.to_dict(),\n",
    "        \"decompressor_model_config\": decompressor.config.to_dict(),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nbJccLQa_TKV"
   },
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "\n",
    "compressor_optimizer = torch.optim.Adam(compressor.parameters(), lr=LR)\n",
    "decompressor_optimizer = torch.optim.Adam(decompressor.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zioTdU4gA2J2"
   },
   "outputs": [],
   "source": [
    "# TODO: increase batch size\n",
    "BATCH_SIZE = 16\n",
    "TOKEN_COST = 0.01\n",
    "train_dataset = dataset\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388,
     "referenced_widgets": [
      "a0678d2428ff4198a9381b664dea08c4",
      "579d2c20323a4e14aa0b2fcc125e9eb9",
      "1a79263283254ba3a8e909ea3966e3ac",
      "e4dcb7f644ce4739b255809f9df0bf53",
      "584d3bd4ac484269bcf7da1d48c78448",
      "e648ad71485b482992d3b5b699fdf90b",
      "a7c81547e14040a28b9f3e8f469bc933",
      "460431870cd346caa15e02b9ffe0c63f",
      "a75e62964f224e8ab32e9136c00f786e",
      "6f20c7b7089045ffa62fda32898dd673",
      "e79223029d27455288e6daa49aabe4f3"
     ]
    },
    "id": "-71bvb9b4Rth",
    "outputId": "058aeb31-300b-4aef-e930-5421113cbff1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c75754c2c9744688471c1a89698d1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import tqdm.auto as tqdm\n",
    "from transformers import GenerationConfig\n",
    "from transformers import modeling_outputs\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    "    max_new_tokens=100,\n",
    "    decoder_start_token_id=compressor.generation_config.decoder_start_token_id,\n",
    "    eos_token_id=compressor.generation_config.eos_token_id,\n",
    "    pad_token_id=compressor.generation_config.pad_token_id,\n",
    "    return_dict_in_generate=True,\n",
    "    output_logits=True,\n",
    "    # output_scores = True,\n",
    ")\n",
    "\n",
    "with tqdm.tqdm(data_loader) as pbar:\n",
    "    for batch in pbar:\n",
    "        input_ids = tokenizer(\n",
    "            batch[\"text\"],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "        ).input_ids.to(device)\n",
    "\n",
    "        compressed = compressor.generate(input_ids=input_ids, generation_config=generation_config)\n",
    "        decompressed = decompressor.forward(input_ids=compressed.sequences, labels=input_ids)\n",
    "\n",
    "        actions = compressed.sequences[..., 1:]\n",
    "        action_distributions = torch.stack(compressed.logits).transpose(0, 1)\n",
    "        values = compressor.forward(input_ids=input_ids, decoder_input_ids=compressed.sequences).value_predictions[..., :-1]\n",
    "        action_mask = actions != generation_config.pad_token_id\n",
    "        # FIX: if we hit generation limit, there would be no <eos> so this would fail\n",
    "        (_, eos_indices) = (actions == generation_config.eos_token_id).nonzero(as_tuple=True)\n",
    "\n",
    "        losses = F.cross_entropy(\n",
    "            decompressed.logits.flatten(0, -2),\n",
    "            target=input_ids.flatten(),\n",
    "            ignore_index=0,\n",
    "            reduction=\"none\",\n",
    "        ).view(input_ids.shape)\n",
    "        decompressor_loss = losses.mean()\n",
    "\n",
    "        sequence_compression_loss = losses.detach().sum(dim=-1)\n",
    "        rewards = torch.where(\n",
    "            actions == generation_config.eos_token_id,\n",
    "            -sequence_compression_loss.unsqueeze(-1),\n",
    "            -TOKEN_COST,\n",
    "        ) * action_mask\n",
    "        qs = rewards.flip(dims=[-1]).cumsum(dim=-1).flip(dims=[-1])\n",
    "\n",
    "        advantage = (qs - values) * action_mask\n",
    "        critic_loss = (advantage * advantage).mean()\n",
    "\n",
    "        action_logits = F.cross_entropy(\n",
    "            action_distributions.flatten(0, -2),\n",
    "            target=actions.flatten(),\n",
    "            ignore_index=0,\n",
    "            reduction=\"none\",\n",
    "        ).view(actions.shape)\n",
    "        actor_loss = (action_logits * advantage.detach()).mean()\n",
    "\n",
    "        pbar.set_description(f\"{critic_loss=:.2f}, {actor_loss=:.2f}, {decompressor_loss=:.2f}\")\n",
    "\n",
    "        compressor_optimizer.zero_grad()\n",
    "        decompressor_optimizer.zero_grad()\n",
    "\n",
    "        (actor_loss + critic_loss).backward()\n",
    "        decompressor_loss.backward()\n",
    "\n",
    "        compressor_optimizer.step()\n",
    "        decompressor_optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"actor_loss\": actor_loss,\n",
    "                    \"critic_loss\": critic_loss,\n",
    "                    \"reward\": rewards.sum(dim=-1).mean(),\n",
    "                    \"decompressor_loss\": decompressor_loss,\n",
    "                    \"accuracy\": (-losses.sum(dim=-1)).exp().mean(),\n",
    "                    \"compressed_size\": eos_indices.float().mean(),\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f322fb112a4a69b3c95ed7e892e3a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.275 MB of 0.275 MB uploaded (0.042 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 9.3%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▅▆▃▆▅▅▅█▂█▄▆▃▆▅▅▂▄▅▇▅▅▇▄▁▆▄▅▄▇█▄▇▇▆▂▇▆▆▆</td></tr><tr><td>actor_loss</td><td>█▄▂▂▁▂▂▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>compressed_size</td><td>▂▁  █                                   </td></tr><tr><td>critic_loss</td><td>█▂▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>decompressor_loss</td><td>▄▃▇▃▄▄▃▁▇▁▆▃▇▂▄▃▇▇▄▁▄▄▂▄▇▄▅▄▅▂▁▅▂▂▃█▂▄▃▃</td></tr><tr><td>reward</td><td>▂▇██▁███████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.81237</td></tr><tr><td>actor_loss</td><td>0.00544</td></tr><tr><td>compressed_size</td><td>nan</td></tr><tr><td>critic_loss</td><td>1e-05</td></tr><tr><td>decompressor_loss</td><td>0.66343</td></tr><tr><td>reward</td><td>-1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Token Training</strong> at: <a href='https://wandb.ai/chihuahuas/DETHCOD/runs/01oc9z80' target=\"_blank\">https://wandb.ai/chihuahuas/DETHCOD/runs/01oc9z80</a><br/> View project at: <a href='https://wandb.ai/chihuahuas/DETHCOD' target=\"_blank\">https://wandb.ai/chihuahuas/DETHCOD</a><br/>Synced 7 W&B file(s), 0 media file(s), 7 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240806_152102-01oc9z80/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor.save_pretrained(MODEL_PATH / \"compressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompressor.save_pretrained(MODEL_PATH / \"decompressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWtEiSe0RZqa",
    "outputId": "e2b87961-8603-48e7-9a72-fecfd1ebec4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"|align=&quot;left&quot;|''[[Medúlla]]''\"\n",
      "reward = -42.99\n",
      "values = [-31.68]\n",
      "advantages = [-11.31]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sample = random.choice(dataset)\n",
    "print(repr(sample[\"text\"]))\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    sample[\"text\"],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    ").input_ids.to(device)\n",
    "\n",
    "compressed = compressor.generate(\n",
    "    input_ids=input_ids,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    compression_output = compressor.forward(\n",
    "        input_ids=input_ids,\n",
    "        decoder_input_ids=compressed,\n",
    "    )\n",
    "\n",
    "with torch.no_grad():\n",
    "    decompressed = decompressor.forward(\n",
    "        input_ids=compressed,\n",
    "        labels=input_ids,\n",
    "    )\n",
    "\n",
    "num_ids = decompressed.logits.size(-1)\n",
    "losses = F.cross_entropy(\n",
    "    decompressed.logits.view(-1, num_ids),\n",
    "    target=input_ids.view(-1),\n",
    "    ignore_index=0,\n",
    "    reduction='none',\n",
    ")\n",
    "\n",
    "preds = torch.argmax(decompressed.logits, dim=-1)\n",
    "\n",
    "TOKEN_COST = 1\n",
    "len_compressed = compressed.shape[1]\n",
    "reward = -TOKEN_COST * len_compressed - losses.detach().sum()\n",
    "\n",
    "value = compression_output.value_predictions.squeeze(-1)\n",
    "value = value[..., :-1]\n",
    "Q = torch.ones_like(value) * reward\n",
    "\n",
    "advantage = Q - value\n",
    "critic_loss = torch.nn.functional.mse_loss(value, Q, reduction='mean')\n",
    "\n",
    "num_ids = compression_output.logits.size(-1)\n",
    "# TODO: add a negative sign if didn't work\n",
    "action_logits = F.cross_entropy(\n",
    "    compression_output.logits[:, :-1].view(-1, num_ids),\n",
    "    target=compressed[:, 1:].view(-1),\n",
    "    ignore_index=0,\n",
    "    reduction='none',\n",
    ")\n",
    "\n",
    "actor_loss = (advantage.detach() * action_logits).mean()\n",
    "decompressor_loss = losses.mean()\n",
    "\n",
    "print(f\"reward = {reward.item():.2f}\")\n",
    "print(f\"values = {value[0].double().round(decimals=2).tolist()}\")\n",
    "print(f\"advantages = {advantage[0].double().round(decimals=2).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad></s>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(compressed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYiKrtM2M03J",
    "outputId": "ccf98ed3-034e-4363-e687-a08941c63c26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-33.48]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLVMLQIqQXCf",
    "outputId": "01a7d128-c502-49f3-9556-fc948ee1f1ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed[0, 1] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = compression_output.logits[0, -1].sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1,     3,   183,  ..., 26948, 31655, 31245], device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1923.3522], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(\n",
    "    compression_output.logits[:, :-1, :].view(-1, num_ids),\n",
    "    target=compressed[:, 1:].flatten(),\n",
    "    ignore_index=0,\n",
    "    reduction='none',\n",
    ") * advantage.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2T85EARPdwI",
    "outputId": "bc324f8e-e86a-44c4-ab3b-a95c72b1cae3"
   },
   "outputs": [],
   "source": [
    "compression_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(action_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GtKo3PPGQf0J",
    "outputId": "b0d3ea63-0a51-43ab-8fa2-e784c530ab45"
   },
   "outputs": [],
   "source": [
    "advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXhr1x1tQhII",
    "outputId": "213f761f-3ea8-4f9a-e857-b7e3ac69a167"
   },
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLAz9DwoN5np",
    "outputId": "b3931440-5067-4716-99b2-9421357bd608"
   },
   "outputs": [],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIKY8_DwNa4l",
    "outputId": "bf6eb955-9a2a-4b57-8db4-6d86a7e94675"
   },
   "outputs": [],
   "source": [
    "len_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zxqYdtCNLn7",
    "outputId": "fb8f9db0-ea93-4a70-be64-dbced88bc02b"
   },
   "outputs": [],
   "source": [
    "advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aDveEsAPMsQt",
    "outputId": "b2edf6d5-b6c8-44fa-99b8-13a4321b5afc"
   },
   "outputs": [],
   "source": [
    "actor_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SiJGEKx2MtlU",
    "outputId": "ad04d0e9-3976-418b-a74f-9a480ce1b48b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128.0074, device='cuda:0')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_loss"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1a79263283254ba3a8e909ea3966e3ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_460431870cd346caa15e02b9ffe0c63f",
      "max": 855090,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a75e62964f224e8ab32e9136c00f786e",
      "value": 1702
     }
    },
    "460431870cd346caa15e02b9ffe0c63f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "579d2c20323a4e14aa0b2fcc125e9eb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e648ad71485b482992d3b5b699fdf90b",
      "placeholder": "​",
      "style": "IPY_MODEL_a7c81547e14040a28b9f3e8f469bc933",
      "value": "actor_loss=-10.76, critic_loss=745.64, decompressor_loss=1.31:   0%"
     }
    },
    "584d3bd4ac484269bcf7da1d48c78448": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f20c7b7089045ffa62fda32898dd673": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0678d2428ff4198a9381b664dea08c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_579d2c20323a4e14aa0b2fcc125e9eb9",
       "IPY_MODEL_1a79263283254ba3a8e909ea3966e3ac",
       "IPY_MODEL_e4dcb7f644ce4739b255809f9df0bf53"
      ],
      "layout": "IPY_MODEL_584d3bd4ac484269bcf7da1d48c78448"
     }
    },
    "a75e62964f224e8ab32e9136c00f786e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a7c81547e14040a28b9f3e8f469bc933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4dcb7f644ce4739b255809f9df0bf53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f20c7b7089045ffa62fda32898dd673",
      "placeholder": "​",
      "style": "IPY_MODEL_e79223029d27455288e6daa49aabe4f3",
      "value": " 1702/855090 [14:03&lt;68:11:10,  3.48it/s]"
     }
    },
    "e648ad71485b482992d3b5b699fdf90b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e79223029d27455288e6daa49aabe4f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
